{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f316bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-4.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2.3.0)\n",
      "Collecting py4j==0.10.9.9 (from pyspark)\n",
      "  Using cached py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.9 pyspark-4.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3809a5",
   "metadata": {},
   "source": [
    "## Synthatic Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee71a59",
   "metadata": {},
   "source": [
    "Creating Product catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adfd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate 100 products\n",
    "products = []\n",
    "for i in range(1, 101):\n",
    "    products.append({\n",
    "        \"product_id\": f\"PRD{str(i).zfill(5)}\",\n",
    "        \"product_name\": random.choice([\"Laptop\", \"Phone\", \"Tablet\", \"Headphones\", \"Monitor\"]),\n",
    "        \"category\": random.choice([\"Electronics\", \"Accessories\", \"Computers\"]),\n",
    "        \"price\": round(random.uniform(50, 2000), 2)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(products).to_csv(\"marketing_data/products/product_catalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be1300",
   "metadata": {},
   "source": [
    "Creating transactions data for each channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9331dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transactions\n",
    "transactions = []\n",
    "start_date = datetime(2024, 1, 1)\n",
    "\n",
    "for i in range(1, 10001):\n",
    "    channel = random.choice([\"web\", \"mobile\", \"instore\"])\n",
    "    transactions.append({\n",
    "        \"transaction_id\": f\"TXN{str(i).zfill(8)}\",\n",
    "        \"product_id\": f\"PRD{str(random.randint(1, 100)).zfill(5)}\",\n",
    "        \"customer_id\": f\"CUST{str(random.randint(1, 500)).zfill(5)}\",\n",
    "        \"amount\": round(random.uniform(10, 5000), 2),\n",
    "        \"channel\": channel,\n",
    "        \"transaction_date\": (start_date + timedelta(days=random.randint(0, 180))).strftime(\"%Y-%m-%d\"),\n",
    "        \"campaign_id\": random.choice([\"CAMPAIGN1\", \"CAMPAIGN2\", None])\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and split by channel\n",
    "transactions_df = pd.DataFrame(transactions)\n",
    "for channel in [\"web\", \"mobile\", \"instore\"]:\n",
    "    transactions_df[transactions_df[\"channel\"] == channel]\\\n",
    "        .to_csv(f\"marketing_data/transactions/{channel}/transactions_{channel}_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0639d162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRD00001</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1100.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRD00002</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>50.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRD00003</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>51.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRD00004</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>Computers</td>\n",
       "      <td>609.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRD00005</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>725.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_name     category    price\n",
       "0   PRD00001       Tablet  Accessories  1100.37\n",
       "1   PRD00002   Headphones  Accessories    50.51\n",
       "2   PRD00003       Laptop  Electronics    51.95\n",
       "3   PRD00004      Monitor    Computers   609.96\n",
       "4   PRD00005       Laptop  Accessories   725.24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"marketing_data/products/product_catalog.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e11f79",
   "metadata": {},
   "source": [
    "uploading to adls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e8edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-file-datalake in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (12.20.0)\n",
      "Requirement already satisfied: dotenv in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: adlfs in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2024.12.0)\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2025.5.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-storage-file-datalake) (1.35.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.25.1 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-storage-file-datalake) (12.25.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-storage-file-datalake) (4.14.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-storage-file-datalake) (0.7.2)\n",
      "Requirement already satisfied: python-dotenv in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: azure-datalake-store<0.1,>=0.0.53 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from adlfs) (0.0.53)\n",
      "Requirement already satisfied: azure-identity in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from adlfs) (1.23.0)\n",
      "Requirement already satisfied: fsspec>=2023.12.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from adlfs) (2025.5.1)\n",
      "Requirement already satisfied: aiohttp>=3.7.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from adlfs) (3.12.13)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs)\n",
      "  Downloading aiobotocore-2.23.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.38.28,>=1.38.23 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading botocore-1.38.27-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.6.3)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from aiohttp>=3.7.0->adlfs) (1.20.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (2.32.4)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (1.17.0)\n",
      "Requirement already satisfied: cffi in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs) (1.17.1)\n",
      "Requirement already satisfied: msal<2,>=1.16.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs) (1.32.3)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-storage-blob>=12.25.1->azure-storage-file-datalake) (45.0.5)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from azure-identity->adlfs) (1.3.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from botocore<1.38.28,>=1.38.23->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.5.0)\n",
      "Requirement already satisfied: pycparser in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs) (2.22)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs) (2.10.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dexter/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-file-datalake) (2025.7.9)\n",
      "Downloading s3fs-2025.5.1-py3-none-any.whl (30 kB)\n",
      "Downloading aiobotocore-2.23.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m979.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Downloading botocore-1.38.27-py3-none-any.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Installing collected packages: wrapt, jmespath, aioitertools, botocore, aiobotocore, s3fs\n",
      "Successfully installed aiobotocore-2.23.0 aioitertools-0.12.0 botocore-1.38.27 jmespath-1.0.1 s3fs-2025.5.1 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-storage-file-datalake dotenv adlfs s3fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e5375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created S3 dir (via .keep): marketing_data/transactions/.keep\n",
      "Created S3 dir (via .keep): marketing_data/products/.keep\n",
      "Created S3 dir (via .keep): marketing_data/transactions/instore/.keep\n",
      "Created S3 dir (via .keep): marketing_data/transactions/mobile/.keep\n",
      "Created S3 dir (via .keep): marketing_data/transactions/web/.keep\n",
      "Uploaded: marketing_data/transactions/instore/transactions_instore_2024.csv → s3://marketing-data-bucket-09/marketing_data/transactions/instore/transactions_instore_2024.csv\n",
      "Uploaded: marketing_data/transactions/mobile/transactions_mobile_2024.csv → s3://marketing-data-bucket-09/marketing_data/transactions/mobile/transactions_mobile_2024.csv\n",
      "Uploaded: marketing_data/transactions/web/transactions_web_2024.csv → s3://marketing-data-bucket-09/marketing_data/transactions/web/transactions_web_2024.csv\n",
      "Uploaded: marketing_data/products/product_catalog.csv → s3://marketing-data-bucket-09/marketing_data/products/product_catalog.csv\n",
      "\n",
      "Final S3 Structure:\n",
      " - marketing-data-bucket-09/marketing_data/products\n",
      "   ├─ marketing-data-bucket-09/marketing_data/products/.keep\n",
      "   ├─ marketing-data-bucket-09/marketing_data/products/product_catalog.csv\n",
      " - marketing-data-bucket-09/marketing_data/transactions\n",
      "   ├─ marketing-data-bucket-09/marketing_data/transactions/.keep\n",
      "   ├─ marketing-data-bucket-09/marketing_data/transactions/instore\n",
      "   ├─ marketing-data-bucket-09/marketing_data/transactions/mobile\n",
      "   ├─ marketing-data-bucket-09/marketing_data/transactions/web\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize S3 filesystem\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    secret=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    client_kwargs={'region_name': os.getenv(\"AWS_REGION\")}\n",
    ")\n",
    "\n",
    "bucket_name = os.getenv(\"AWS_BUCKET_NAME\")\n",
    "local_base = \"marketing_data\"  # Your local mock data directory\n",
    "\n",
    "# Create empty output folders (S3 doesn't have true dirs, use dummy files)\n",
    "def create_s3_dir(s3_path):\n",
    "    dummy_file = f\"{s3_path}/.keep\"\n",
    "    fs.touch(f\"{bucket_name}/{dummy_file}\")\n",
    "    print(f\"Created S3 dir (via .keep): {dummy_file}\")\n",
    "\n",
    "# Upload function\n",
    "def upload_to_s3(local_path: str):\n",
    "    relative_path = Path(local_path).relative_to(local_base)\n",
    "    s3_path = f\"{bucket_name}/marketing_data/{relative_path.as_posix()}\"\n",
    "\n",
    "    if os.path.isdir(local_path):\n",
    "        create_s3_dir(f\"marketing_data/{relative_path.as_posix()}\")\n",
    "    else:\n",
    "        with open(local_path, \"rb\") as f:\n",
    "            fs.put(local_path, s3_path)\n",
    "            print(f\"Uploaded: {local_path} → s3://{s3_path}\")\n",
    "\n",
    "# Walk through local directory\n",
    "for root, dirs, files in os.walk(local_base):\n",
    "    # Create S3 directories\n",
    "    for dir_name in dirs:\n",
    "        upload_to_s3(os.path.join(root, dir_name))\n",
    "    \n",
    "    # Upload files\n",
    "    for file_name in files:\n",
    "        upload_to_s3(os.path.join(root, file_name))\n",
    "\n",
    "# Verification: Print all top-level objects\n",
    "print(\"\\nFinal S3 Structure:\")\n",
    "for path in fs.ls(f\"{bucket_name}/marketing_data\", detail=False):\n",
    "    print(f\" - {path}\")\n",
    "    if fs.isdir(path):\n",
    "        for subpath in fs.ls(path, detail=False):\n",
    "            print(f\"   ├─ {subpath}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
